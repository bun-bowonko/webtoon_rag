{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "086c6903-0863-4aed-b82c-7b43ff25b07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bun.2/.cache/pypoetry/virtualenvs/poetry-env-eDEwtiIl-py3.10/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1820: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:00<00:00, 18197.61it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "import bs4\n",
    "import ssl\n",
    "import urllib3\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import os\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "def instruct_structure(prompt):\n",
    "    input_text, output_text = prompt.split('### target')\n",
    "    input_text = input_text.replace('### glossaries', '### glossary').replace('\\n* ', '\\n• ')\n",
    "    input_text = re.sub(r\"\\[[^\\]]+\\] \", \"[UNK] \", input_text)\n",
    "    return input_text\n",
    "\n",
    "project_id = \"prod-ai-project\"\n",
    "\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project=project_id)\n",
    "sql = \"\"\"select series_id, episode_id, org_input_text, org_output_text, prompt \n",
    "        from webtoon_translation.structured_240820_ep_line\n",
    "        where data_split = 'romance_valid'\"\"\"\n",
    "df = client.query(sql).result().to_dataframe()\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "df['prompt'] = df['prompt'].progress_apply(lambda x: instruct_structure(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c73691-4be7-4d35-9fbc-d5103529409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def substring_containment(s1, s2, penta_weight = 5, quad_weight=4, tri_weight=3, bi_weight=2, char_weight=1):\n",
    "    def get_ngrams(s, n):\n",
    "        s = ''.join(s.split()) #space 제거  \n",
    "        return {s[i:i+n] for i in range(len(s) - (n-1))}\n",
    "\n",
    "    s1_char = get_ngrams(s1, 1)\n",
    "    s2_char = get_ngrams(s2, 1)\n",
    "    \n",
    "    s1_bigrams = get_ngrams(s1, 2)\n",
    "    s2_bigrams = get_ngrams(s2, 2)\n",
    "    \n",
    "    s1_trigrams = get_ngrams(s1, 3)\n",
    "    s2_trigrams = get_ngrams(s2, 3)\n",
    "\n",
    "    s1_quadgrams = get_ngrams(s1, 4)\n",
    "    s2_quadgrams = get_ngrams(s2, 4)\n",
    "\n",
    "    s1_pentagrams = get_ngrams(s1, 5)\n",
    "    s2_pentagrams = get_ngrams(s2, 5)\n",
    "\n",
    "    #char 계산\n",
    "    common_char = s1_char & s2_char\n",
    "    char_score = len(common_char)\n",
    "    \n",
    "    # bi-gram 포함도 계산\n",
    "    common_bigrams = s1_bigrams & s2_bigrams\n",
    "    bigram_score = len(common_bigrams)\n",
    "\n",
    "    # tri-gram 포함도 계산\n",
    "    common_trigrams = s1_trigrams & s2_trigrams\n",
    "    trigram_score = len(common_trigrams)\n",
    "\n",
    "    # quad-gram 포함도 계산\n",
    "    common_quadgrams = s1_quadgrams & s2_quadgrams\n",
    "    quadgram_score = len(common_quadgrams)\n",
    "\n",
    "    # penta-gram 포함도 계산\n",
    "    common_pentagrams = s1_pentagrams & s2_pentagrams\n",
    "    pentagram_score = len(common_pentagrams)\n",
    "\n",
    "    # 최종 점수 계산 \n",
    "    # 공통 부분이 많을수록 점수가 커지고, 적을수록 점수가 작아지는 구조\n",
    "    # 공통 부분이 많을수록 n-gram의 교집합 크기가 커지고, 가중치가 반영되면서 점수가 높아짐.\n",
    "    # 공통 부분이 적으면 교집합 크기가 작아지고, 동일한 분모(가중치 합)로 나누니까 값이 작아짐.\n",
    "    denominator = char_weight + bi_weight + tri_weight + quad_weight + penta_weight\n",
    "    numerator = char_weight * char_score + \\\n",
    "                 bi_weight * bigram_score + \\\n",
    "                 tri_weight * trigram_score + \\\n",
    "                 quad_weight * quadgram_score + \\\n",
    "                 penta_weight * pentagram_score\n",
    "    final_score = numerator / denominator\n",
    "    \n",
    "    return final_score\n",
    "\n",
    "def adjusted_edit_distance(s1, s2):\n",
    "    \"\"\"Levenshtein 거리 기반 + 공통 단어 + 포함도 반영\"\"\"\n",
    "    containment_ratio = substring_containment(s1, s2)\n",
    "\n",
    "    # 겹치는 문자가 없으면 후보 제외\n",
    "    if containment_ratio == 0:\n",
    "        return -float('inf')\n",
    "        \n",
    "    adjusted_distance = containment_ratio\n",
    "\n",
    "    return adjusted_distance\n",
    "\n",
    "def find_most_similar_sentence(target, sentences):\n",
    "    \"\"\"주어진 문장 목록에서 target 문장과 가장 유사한 문장을 찾음\"\"\"\n",
    "    similarities = []\n",
    "    for sentence in sentences:\n",
    "        #길이 3이내로 차이나는 것만 담기\n",
    "        if len(target) >= len(sentence) + 3:\n",
    "            #print(len(sentence), len(target))\n",
    "            similarities.append((sentence, adjusted_edit_distance(target, sentence)))\n",
    "    similarities.sort(key=lambda x: x[1],reverse=True)  # 거리 기준 정렬 (높을수록 유사)\n",
    "    return similarities[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6054ef-1ce0-4c6d-b7dd-a7d287234bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('가까운 무덤을 보다', 0.7333333333333333), ('무덤을 파다', 0.6666666666666666), ('자기 무덤을 파다', 0.6666666666666666)]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./data/idiom_dict.txt\"\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "origin_lines = [line.split('>')[0].strip() for line in lines]\n",
    "question = '내 무덤을 내가 팠지...'\n",
    "result = find_most_similar_sentence(question, origin_lines)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63766c80-c760-4646-869b-787ee810fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_top(question):\n",
    "    file_path = \"./data/idiom_dict.txt\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    origin_lines = [line.split('>')[0].strip() for line in lines]\n",
    "\n",
    "    result = find_most_similar_sentence(question, origin_lines)\n",
    "    #문법적 유사성 판단 결과 \n",
    "    #1점 이하는 문법적 유사성이 낮다고 판단\n",
    "    SYNTATIC_THRESHOLD = 1.0\n",
    "    result = [r[0] for r in result if r[1] > SYNTATIC_THRESHOLD]\n",
    "    #문법적 유사성으로 1차 필터링\n",
    "    print('문장 : ',question)\n",
    "    print('문법적으로 유사한 후보군들 : ',result[:3])\n",
    "    if len(result) == 0:\n",
    "        return None\n",
    "\n",
    "    #의미적 유사성 비교\n",
    "    docs = [Document(page_content=f\"{line}\") for line in result]\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"nlpai-lab/KURE-v1\")\n",
    "    #embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")\n",
    "\n",
    "    vectorstore = FAISS.from_documents(documents=docs, embedding=embeddings)\n",
    "    retriever = vectorstore.as_retriever(search_type='similarity', search_kwargs={'k': 5})\n",
    "    docs_with_scores = retriever.vectorstore.similarity_search_with_score(question, k=5)\n",
    "    print(docs_with_scores)\n",
    "    doc = docs_with_scores[0][0]\n",
    "    score = docs_with_scores[0][1]\n",
    "    \n",
    "    if hasattr(vectorstore, \"index\") and isinstance(vectorstore.index, faiss.Index):\n",
    "        # FAISS 인덱스를 CPU로 변환 (GPU 해제)\n",
    "        vectorstore.index = faiss.index_gpu_to_cpu(vectorstore.index)\n",
    "    \n",
    "    # FAISS 객체 삭제\n",
    "    del vectorstore\n",
    "    # Python 가비지 컬렉션 실행\n",
    "    gc.collect()\n",
    "    # PyTorch GPU 캐시 정리\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    #2차 필터링, 의미적으로 가장 유사한 대상 중 0.6이하만 (L2 distance는 작을 수록 유사)\n",
    "    SEMANTIC_THRESHOLD = 0.9\n",
    "    if score < SEMANTIC_THRESHOLD:\n",
    "        return (doc.page_content, score)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0fbb0d6-769a-4e9e-ae71-0069e7fd65f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_idx = 4\n",
    "data = df['prompt'][data_idx]\n",
    "example = data.split(\"### source\")[1].strip()\n",
    "#print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d41dc308-8ba8-4495-955c-b8229819f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(find_most_similar_sentence(\"왜 남주가 벌써 내 코앞에서 굴러다니고 있는 거지?\",[\"코 앞이다\"]))\n",
    "# print(find_most_similar_sentence(\"한가지 억울한 점이 있다면\",[\"싹이 있다\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39d55319-a3db-4cf0-9ac5-a12393ddebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(substring_containment(\"왜 남주가 벌써 내 코앞에서 굴러다니고 있는 거지?\", \"코 앞이다\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1833eeb0-f64d-4ebb-8c9f-96887c883d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(extract_top(\"그를 눈엣가시처럼 여겨 죽이고 싶어 하는 자들은 많았다.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b48ee116-a654-495f-b1c9-709fcc2ec1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = ['눈엣가시처럼 여기다', '눈엣가시다', '눈엣가시 같다']\n",
    "# docs = [Document(page_content=f\"{line}\") for line in result]\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"nlpai-lab/KURE-v1\")\n",
    "# #embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")\n",
    "# vectorstore = FAISS.from_documents(documents=docs, embedding=embeddings)\n",
    "# retriever = vectorstore.as_retriever(search_type='similarity', search_kwargs={'k': 5})\n",
    "# question = \"그를 눈엣가시처럼 여겨 죽이고 싶어 하는 자들은 많았다.\"\n",
    "# docs_with_scores = retriever.vectorstore.similarity_search_with_score(question, k=5)\n",
    "# for d, s in docs_with_scores:\n",
    "#     print(d.page_content, s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81a0c04e-c6d5-437a-8415-8dc60ea729a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(find_most_similar_sentence('지긋지긋했던 내 인생에서 가장 평화로운 광경이었다.', ['지긋지긋하다.']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5b7dcb8-07a7-4dba-8e86-1d2e0d3bedf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 :  외로웠다.\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  누군가 날 필요로 해주면 좋겠다고 생각했다.\n",
      "문법적으로 유사한 후보군들 :  ['늦었다고 생각할 때가 가장 빠르다', '늦었다고 생각할 때가 가장 빠를 때다', '늦었다고 생각할 때가 가장 빠른 때다']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2156100/1622343026.py:20: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"nlpai-lab/KURE-v1\")\n",
      "/home/bun.2/.cache/pypoetry/virtualenvs/poetry-env-eDEwtiIl-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(id='15d896fd-6405-4559-91a7-98b17d8fdb94', metadata={}, page_content='늦었다고 생각할 때가 가장 빠르다'), 1.015663), (Document(id='aca9cac4-a0c3-481b-aac7-b204cc894a55', metadata={}, page_content='늦었다고 생각할 때가 가장 빠른 때다'), 1.0195477), (Document(id='577691f7-5dfa-44db-9212-61225fc6a971', metadata={}, page_content='늦었다고 생각할 때가 가장 빠를 때다'), 1.0240672)]\n",
      "\n",
      "문장 :  이 벌레만도 못한 목숨이라도 의미가 있을까?\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  시간이 지나고, 용병단은 헤일론 영지의 방어를 맡게 되었다.\n",
      "문법적으로 유사한 후보군들 :  ['시간이 살같이 지나가다', '시간이 쏜살같이 지나가다']\n",
      "[(Document(id='2d7c3d52-d4d9-4797-be0b-f5f897169a64', metadata={}, page_content='시간이 쏜살같이 지나가다'), 1.0867926), (Document(id='27be14ca-69be-4fc1-bc33-80d456c96c83', metadata={}, page_content='시간이 살같이 지나가다'), 1.1527063)]\n",
      "\n",
      "문장 :  마물과의 싸움은 위험했지만, 돈이 됐다.\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  나는 제대로 된 무기도 받지 못하고,\n",
      "문법적으로 유사한 후보군들 :  ['숲을 보지 못하고 나무만 본다', '제대로 된 밥벌이를 하다']\n",
      "[(Document(id='184cc738-b085-4748-bbf3-1342adf280db', metadata={}, page_content='숲을 보지 못하고 나무만 본다'), 0.9339523), (Document(id='350d7b3e-02b6-4452-8b3b-a19b2641763d', metadata={}, page_content='제대로 된 밥벌이를 하다'), 0.9964077)]\n",
      "\n",
      "문장 :  전장에서 주운 누군가의 검으로 버텼다.\n",
      "문법적으로 유사한 후보군들 :  ['길거리에서 주운 사람 아니다']\n",
      "[(Document(id='f07023e4-1a78-4e29-8cb6-2d9529a3990f', metadata={}, page_content='길거리에서 주운 사람 아니다'), 0.9295497)]\n",
      "\n",
      "문장 :  끝도 없는 고단한 싸움의 좋은 점이 있다면\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  생사를 넘는 전투로 강해졌다는 것일까.\n",
      "문법적으로 유사한 후보군들 :  ['생사를 넘나들다']\n",
      "[(Document(id='7b469323-b3a5-43c8-a08d-1faa21862303', metadata={}, page_content='생사를 넘나들다'), 0.8000559)]\n",
      "생사를 넘나들다 0.8000559\n",
      "\n",
      "문장 :  살아남았다.\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  하지만, 기어코 일은 터졌다.\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  밀리고 있어.\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  즉시 퇴각해!\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  철수다, 철수!\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  거기서 뭐 하는 거냐! 굼뜬 자식!\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  하, 쓸모가 없다면…\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  인간 방패라도 되라고!\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  살아야 한다,\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  시그렌.\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  살아야 한다…\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  살기 위해 버텼다.\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  하지만 아무리 실력이 늘었다고 한들,\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  역부족이었다.\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  드디어 죽는 건가.\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  어쩐지 안심되기까지 한다.\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  한가지 억울한 점이 있다면\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  그딴 쓰레기 같은 놈을 대신해 죽는다는 거다.\n",
      "문법적으로 유사한 후보군들 :  ['쓰레기 같은 말을 하다', '허접 쓰레기 같다', '허접쓰레기 같다']\n",
      "[(Document(id='a1545ac1-ecb3-40f5-b783-1587d847b419', metadata={}, page_content='쓰레기 같은 말을 하다'), 0.6339061), (Document(id='91f0f6df-5585-4e6c-9065-247bcdb90968', metadata={}, page_content='허접 쓰레기 같다'), 0.73261225), (Document(id='bd87dde8-1309-4502-9a0f-edefb1b7eaee', metadata={}, page_content='허접쓰레기 같다'), 0.75386786)]\n",
      "쓰레기 같은 말을 하다 0.6339061\n",
      "\n",
      "문장 :  기왕 누군가를 위해 죽는다면,\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  나와 비슷한 처지의 사람을 구하고 싶었는데…\n",
      "문법적으로 유사한 후보군들 :  ['비슷한 처지다', '비슷한 처지', '아랫사람을 구박하다']\n",
      "[(Document(id='e4c22600-9680-470e-8dff-00362a1aa343', metadata={}, page_content='비슷한 처지'), 0.58117497), (Document(id='03ea787f-cb2a-4c36-a66d-262af4e6f914', metadata={}, page_content='비슷한 처지다'), 0.62783605), (Document(id='6894d28b-fe46-4aa4-a3cd-b353f8e62549', metadata={}, page_content='아랫사람을 구박하다'), 0.8595051)]\n",
      "비슷한 처지 0.58117497\n",
      "\n",
      "문장 :  그래. 좀 더 도움이 필요한 사람,\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  약한 사람에게 손길을 내밀고 싶었어.\n",
      "문법적으로 유사한 후보군들 :  ['따뜻한 손길을 내밀다', '도움의 손길을 내밀다', '구조 손길을 내밀다']\n",
      "[(Document(id='ef218580-9348-46a2-8e22-f9708a795171', metadata={}, page_content='도움의 손길을 내밀다'), 0.57640153), (Document(id='a18f3700-95e0-48b9-92bb-8c7958f609ee', metadata={}, page_content='따뜻한 손길을 내밀다'), 0.6106484), (Document(id='40b002cb-f823-480b-b1a7-71084ae668b6', metadata={}, page_content='구조 손길을 내밀다'), 0.7539414)]\n",
      "도움의 손길을 내밀다 0.57640153\n",
      "\n",
      "문장 :  왜냐면 내가 고독했을 때는 누구도 도움을 주지 않았으니까.\n",
      "문법적으로 유사한 후보군들 :  ['도움을 주고도 욕먹는다', '울지 않는 아이에게 젖을 주지 않는다', '눈길을 주지 않다']\n",
      "[(Document(id='50122222-645b-4c28-bea2-995750c04d2b', metadata={}, page_content='도움을 주고도 욕먹는다'), 0.8945056), (Document(id='55fd6326-8aa7-424e-8115-1b410d28d777', metadata={}, page_content='울지 않는 아이에게 젖을 주지 않는다'), 1.0971569), (Document(id='d5a00107-84b4-4441-bd57-9f80d0b0033c', metadata={}, page_content='눈길을 주지 않다'), 1.2001891)]\n",
      "도움을 주고도 욕먹는다 0.8945056\n",
      "\n",
      "문장 :  그러니 적어도 나는 도움을 주고 싶었어.\n",
      "문법적으로 유사한 후보군들 :  ['도움을 주고도 욕먹는다', '도움을 주다']\n",
      "[(Document(id='679fb2f3-d186-4c24-b1a8-46207b8746a8', metadata={}, page_content='도움을 주다'), 0.5590266), (Document(id='72264518-d363-42a4-9837-3cde8faee700', metadata={}, page_content='도움을 주고도 욕먹는다'), 0.86710536)]\n",
      "도움을 주다 0.5590266\n",
      "\n",
      "문장 :  누군가 나처럼 살지 않기를 바라는 건 나약해.\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  그런 생각이나 하니 결국 이렇게 죽는 거야.\n",
      "문법적으로 유사한 후보군들 :  ['본전 생각이 나다', '톡톡히 본전 생각이 나다']\n",
      "[(Document(id='d3165b76-f385-44e3-9dd3-0197610d7422', metadata={}, page_content='톡톡히 본전 생각이 나다'), 0.94290775), (Document(id='87dcbc86-81bd-412c-9701-95e832eb61b9', metadata={}, page_content='본전 생각이 나다'), 0.96969575)]\n",
      "\n",
      "문장 :  그래도 내 소망이 헛된 게 아니라고 믿고 싶어.\n",
      "문법적으로 유사한 후보군들 :  ['이런 게 아니라 저런 것도 있다', '걷는 게 아니라 날아다니다', '아닌 게 아니라']\n",
      "[(Document(id='a1be59b9-af6d-40c3-a6ed-5b1b01d2e196', metadata={}, page_content='걷는 게 아니라 날아다니다'), 1.0688528), (Document(id='edad3afd-2b95-400b-95a1-558d5f4c19f8', metadata={}, page_content='아닌 게 아니라'), 1.0790075), (Document(id='ee6020e5-2961-400c-9f5f-e1b459ee2547', metadata={}, page_content='이런 게 아니라 저런 것도 있다'), 1.0920664)]\n",
      "\n",
      "문장 :  어딘가에 빛이 있을 거라고.\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  아니면 내가 누군가의 빛이 되고 싶어.\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  이제는 불가능한 일이지만.\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  누군가 어둠 속에서 내 머리를 쓰다듬는다.\n",
      "문법적으로 유사한 후보군들 :  ['머리를 쓰다듬다', '어둠 속에서 길을 찾다', '어둠 속에서 헤매다']\n",
      "[(Document(id='77921e71-16bb-4663-8459-b69cbedfa840', metadata={}, page_content='머리를 쓰다듬다'), 0.42684916), (Document(id='57b380a1-2011-4555-8d3c-a15b4fe5e4b9', metadata={}, page_content='어둠 속에서 헤매다'), 0.5635137), (Document(id='137a7b1e-271c-4997-b6b6-36c2a2ac1dbd', metadata={}, page_content='어둠 속에서 길을 찾다'), 0.5906291)]\n",
      "머리를 쓰다듬다 0.42684916\n",
      "\n",
      "문장 :  눈물이 나올 정도로 다정한 손길로….\n",
      "문법적으로 유사한 후보군들 :  ['금방이라도 눈물이 나올 것 같다', '눈물이 나다', '눈에서 피눈물이 나다']\n",
      "[(Document(id='a32e14e2-85a7-4064-846e-2add985a2380', metadata={}, page_content='눈물이 나다'), 0.7100053), (Document(id='de70a45b-2f74-4bcc-aa52-e0bf3bace2ad', metadata={}, page_content='금방이라도 눈물이 나올 것 같다'), 0.7432751), (Document(id='a11b0a5d-f208-4963-8574-ea7fc3cfa250', metadata={}, page_content='눈에서 피눈물이 나다'), 0.8422279)]\n",
      "눈물이 나다 0.7100053\n",
      "\n",
      "문장 :  여긴… 어디지?\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  어?\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  여자애…?\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  그건\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  지긋지긋했던 내 인생에서 가장 평화로운 광경이었다.\n",
      "문법적으로 유사한 후보군들 :  ['지긋지긋하다']\n",
      "[(Document(id='653f33c7-295b-423b-9731-6b96f261214f', metadata={}, page_content='지긋지긋하다'), 0.7663729)]\n",
      "지긋지긋하다 0.7663729\n",
      "\n",
      "문장 :  상처는 괜찮아?\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  괜찮은지 한번 보자.\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  멋대로 건들지 말라니까.\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n",
      "문장 :  그래도…\n",
      "문법적으로 유사한 후보군들 :  []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sens = example.split('\\n')\n",
    "hints = []\n",
    "for sen in sens:\n",
    "    q = sen.split('[UNK]')[1].strip()\n",
    "    result = extract_top(q)\n",
    "    if result:\n",
    "        idiom = result[0]\n",
    "        print(idiom, result[1])\n",
    "        print()\n",
    "        hints.append(idiom)\n",
    "    else:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5ccc372-93fc-41dd-bb45-edddcc822270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['생사를 넘나들다', '쓰레기 같은 말을 하다', '비슷한 처지', '도움의 손길을 내밀다', '도움을 주고도 욕먹는다', '도움을 주다', '머리를 쓰다듬다', '눈물이 나다', '지긋지긋하다']\n"
     ]
    }
   ],
   "source": [
    "print(hints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8daa3337-f7de-4562-a063-69fce40a8da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./data/idiom_dict.txt\"\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "origin_lines = [line.split('>')[0].strip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89e4cc70-e3f2-4d0e-b073-854711508c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000\t[UNK] 외로웠다.\n",
      "가슴이 뜨겁다 > Have a passionate heart\n",
      "가슴이 뜨겁다\n"
     ]
    }
   ],
   "source": [
    "print(sens[0])\n",
    "print(lines[0].strip())\n",
    "print(origin_lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2e18e15-b170-44bb-a24a-0298a09f16e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hints_origin = []\n",
    "for h in hints:\n",
    "    for line in lines:\n",
    "        if h in line:\n",
    "            hints_origin.append(line.strip())\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd8d37c6-89a5-4773-be52-0ddad04e474d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['생사를 넘나들다 > Be in a dangerous situation', '쓰레기 같은 말을 하다 > Speak nonsense', '비슷한 처지다 > Be in the same boat', '도움의 손길을 내밀다 > Offer a helping hand', '도움을 주고도 욕먹는다 > No good deed goes unpunished', '도움을 주다 > Give a helping hand', '머리를 쓰다듬다 > Comfort someone', '눈물이 나다 > Feel emotional', '지긋지긋하다 > Be sick and tired of']\n"
     ]
    }
   ],
   "source": [
    "print(hints_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3d5235a-65c5-4b07-8166-e936b8382c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = data.split(\"### source\")[0].strip()+'\\n'\n",
    "for i in range(len(hints_origin)):\n",
    "    prompt += '• '+hints_origin[i]+'\\n'\n",
    "input_text = prompt + '\\n\\n###source\\n' + example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8daae5f2-4f15-4870-b69e-8ad88094f392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### glossary\n",
      "• 용병: mercenaries\n",
      "• 시그렌 (M): siegren\n",
      "• 생사를 넘나들다 > Be in a dangerous situation\n",
      "• 쓰레기 같은 말을 하다 > Speak nonsense\n",
      "• 비슷한 처지다 > Be in the same boat\n",
      "• 도움의 손길을 내밀다 > Offer a helping hand\n",
      "• 도움을 주고도 욕먹는다 > No good deed goes unpunished\n",
      "• 도움을 주다 > Give a helping hand\n",
      "• 머리를 쓰다듬다 > Comfort someone\n",
      "• 눈물이 나다 > Feel emotional\n",
      "• 지긋지긋하다 > Be sick and tired of\n",
      "\n",
      "\n",
      "###source\n",
      "000\t[UNK] 외로웠다.\n",
      "001\t[UNK] 누군가 날 필요로 해주면 좋겠다고 생각했다.\n",
      "002\t[UNK] 이 벌레만도 못한 목숨이라도 의미가 있을까?\n",
      "003\t[UNK] 시간이 지나고, 용병단은 헤일론 영지의 방어를 맡게 되었다.\n",
      "004\t[UNK] 마물과의 싸움은 위험했지만, 돈이 됐다.\n",
      "005\t[UNK] 나는 제대로 된 무기도 받지 못하고,\n",
      "006\t[UNK] 전장에서 주운 누군가의 검으로 버텼다.\n",
      "007\t[UNK] 끝도 없는 고단한 싸움의 좋은 점이 있다면\n",
      "008\t[UNK] 생사를 넘는 전투로 강해졌다는 것일까.\n",
      "009\t[UNK] 살아남았다.\n",
      "010\t[UNK] 하지만, 기어코 일은 터졌다.\n",
      "011\t[UNK] 밀리고 있어.\n",
      "012\t[UNK] 즉시 퇴각해!\n",
      "013\t[UNK] 철수다, 철수!\n",
      "014\t[UNK] 거기서 뭐 하는 거냐! 굼뜬 자식!\n",
      "015\t[UNK] 하, 쓸모가 없다면…\n",
      "016\t[UNK] 인간 방패라도 되라고!\n",
      "017\t[UNK] 살아야 한다,\n",
      "018\t[UNK] 시그렌.\n",
      "019\t[UNK] 살아야 한다…\n",
      "020\t[UNK] 살기 위해 버텼다.\n",
      "021\t[UNK] 하지만 아무리 실력이 늘었다고 한들,\n",
      "022\t[UNK] 역부족이었다.\n",
      "023\t[UNK] 드디어 죽는 건가.\n",
      "024\t[UNK] 어쩐지 안심되기까지 한다.\n",
      "025\t[UNK] 한가지 억울한 점이 있다면\n",
      "026\t[UNK] 그딴 쓰레기 같은 놈을 대신해 죽는다는 거다.\n",
      "027\t[UNK] 기왕 누군가를 위해 죽는다면,\n",
      "028\t[UNK] 나와 비슷한 처지의 사람을 구하고 싶었는데…\n",
      "029\t[UNK] 그래. 좀 더 도움이 필요한 사람,\n",
      "030\t[UNK] 약한 사람에게 손길을 내밀고 싶었어.\n",
      "031\t[UNK] 왜냐면 내가 고독했을 때는 누구도 도움을 주지 않았으니까.\n",
      "032\t[UNK] 그러니 적어도 나는 도움을 주고 싶었어.\n",
      "033\t[UNK] 누군가 나처럼 살지 않기를 바라는 건 나약해.\n",
      "034\t[UNK] 그런 생각이나 하니 결국 이렇게 죽는 거야.\n",
      "035\t[UNK] 그래도 내 소망이 헛된 게 아니라고 믿고 싶어.\n",
      "036\t[UNK] 어딘가에 빛이 있을 거라고.\n",
      "037\t[UNK] 아니면 내가 누군가의 빛이 되고 싶어.\n",
      "038\t[UNK] 이제는 불가능한 일이지만.\n",
      "039\t[UNK] 누군가 어둠 속에서 내 머리를 쓰다듬는다.\n",
      "040\t[UNK] 눈물이 나올 정도로 다정한 손길로….\n",
      "041\t[UNK] 여긴… 어디지?\n",
      "042\t[UNK] 어?\n",
      "043\t[UNK] 여자애…?\n",
      "044\t[UNK] 그건\n",
      "045\t[UNK] 지긋지긋했던 내 인생에서 가장 평화로운 광경이었다.\n",
      "046\t[UNK] 상처는 괜찮아?\n",
      "047\t[UNK] 괜찮은지 한번 보자.\n",
      "048\t[UNK] 멋대로 건들지 말라니까.\n",
      "049\t[UNK] 그래도…\n"
     ]
    }
   ],
   "source": [
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d0a463f-fa36-47cf-93a0-87bbe9a62502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "GPT_FINE_TUNING_MODEL=\"ft:gpt-4o-2024-08-06:kakaoent:webtoon-sft-250225:B4j839q0\"\n",
    "openai_client = OpenAI(\n",
    "    api_key='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "278720a2-1a3a-47ed-a182-02c819e981a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"You're an expert translator who translates Korean webtoon in English. Make sure the number of target sentences matches the number of source sentences. The result should be TSV formatted. \n",
    "            • Find a balance between staying true to the Korean meaning and keeping a natural flow. Don't be afraid to add to the text. Embellish it. \n",
    "            • Avoid translating word-for-word. Keep the general feeling and translate the text accordingly. \n",
    "            • Translate with an American audience in mind. This means easy-to-read, conversational English.\n",
    "            • Please translate using ### glossary.\"\"\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "chat_completion = openai_client.beta.chat.completions.parse(\n",
    "    model= GPT_FINE_TUNING_MODEL,\n",
    "    messages = [\n",
    "        SYSTEM_PROMPT,\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\" : [{\"type\" : \"text\",\n",
    "                          \"text\" : input_text\n",
    "                        }],\n",
    "        }\n",
    "    ],\n",
    "    temperature= 0.2,\n",
    "    top_p = 0.8\n",
    ")\n",
    "response = chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "585faac5-c516-441e-b996-baa929d285f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000\tI was lonely.\n",
      "001\tI wished someone would need me.\n",
      "002\twould that give my worthless life some meaning?\n",
      "003\tas time passed, the mercenary troop was assigned to defend the barony of hailon.\n",
      "004\tfighting the demons was dangerous, but it paid well.\n",
      "005\tI wasn’t given a proper weapon,\n",
      "006\tso I had to make do with a sword I found on the battlefield.\n",
      "007\tif there was any good that came out of the endless, grueling battles,\n",
      "008\tit was that I became stronger by being in a dangerous situation.\n",
      "009\tI survived.\n",
      "010\tbut eventually, it happened.\n",
      "011\twe’re being pushed back.\n",
      "012\tretreat immediately!\n",
      "013\tretreat, retreat!\n",
      "014\twhat are you doing there, you slowpoke?!\n",
      "015\thaa, if you’re that useless,\n",
      "016\tyou might as well become a human shield!\n",
      "017\tyou must survive,\n",
      "018\tsiegren.\n",
      "019\tyou must survive...\n",
      "020\tI endured to stay alive.\n",
      "021\tbut no matter how much stronger I became,\n",
      "022\tit wasn’t enough.\n",
      "023\tam I finally going to die?\n",
      "024\tI feel strangely relieved.\n",
      "025\tif there’s one thing I regret,\n",
      "026\tit’s that I’m dying in place of that piece of trash.\n",
      "027\tif I had to die for someone,\n",
      "028\tI would have wanted to save someone who was in the same boat as me...\n",
      "029\tyes, I wanted to offer a helping hand...\n",
      "030\t...to someone who needed it more, someone weaker.\n",
      "031\tbecause when I was alone, no one gave me a helping hand.\n",
      "032\tso I wanted to help someone, at the very least.\n",
      "033\tI was weak to wish that no one would live a life like mine.\n",
      "034\tthat’s why I’m dying like this.\n",
      "035\tstill, I want to believe that my wish wasn’t in vain.\n",
      "036\tI want to believe that there’s light somewhere.\n",
      "037\tif not, I want to become someone’s light.\n",
      "038\tthough that’s impossible now.\n",
      "039\tsomeone is patting my head in the darkness.\n",
      "040\tthey’re so gentle that I feel emotional...\n",
      "041\twhere... am I?\n",
      "042\thuh?\n",
      "043\ta girl...?\n",
      "044\tit was...\n",
      "045\t...the most peaceful sight in my miserable life.\n",
      "046\tare your wounds okay?\n",
      "047\tlet me see if you’re alright.\n",
      "048\tI told you not to touch me.\n",
      "049\tbut still...\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b38c23-c10f-483f-b048-7db47d45b0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128a2711-cbf9-4796-bb17-1462460a3a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
