{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0a32808-4ed9-4dbd-b84d-5cd451918ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "from accelerate import init_empty_weights\n",
    "\n",
    "model_name = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "\n",
    "# with init_empty_weights():  # GPU 메모리 하나도 안 씀\n",
    "#     model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# # 구조만 출력\n",
    "# for name, module in model.named_modules():\n",
    "#     if \"experts\" in name:\n",
    "#         print(name, type(module))\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"meta-llama/Llama-4-Maverick-17B-128E-Instruct\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d8bfee-fb93-467a-89fe-fdde9644b3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama4Config {\n",
      "  \"architectures\": [\n",
      "    \"Llama4ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"boi_token_index\": 200080,\n",
      "  \"eoi_token_index\": 200081,\n",
      "  \"image_token_index\": 200092,\n",
      "  \"model_type\": \"llama4\",\n",
      "  \"text_config\": {\n",
      "    \"_attn_implementation_autoset\": true,\n",
      "    \"attention_bias\": false,\n",
      "    \"attention_chunk_size\": 8192,\n",
      "    \"attention_dropout\": 0.0,\n",
      "    \"attn_scale\": 0.1,\n",
      "    \"attn_temperature_tuning\": 4,\n",
      "    \"bos_token_id\": 200000,\n",
      "    \"cache_implementation\": \"hybrid\",\n",
      "    \"eos_token_id\": [\n",
      "      200001,\n",
      "      200007,\n",
      "      200008\n",
      "    ],\n",
      "    \"floor_scale\": 8192,\n",
      "    \"for_llm_compressor\": false,\n",
      "    \"head_dim\": 128,\n",
      "    \"hidden_act\": \"silu\",\n",
      "    \"hidden_size\": 5120,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"interleave_moe_layer_step\": 2,\n",
      "    \"intermediate_size\": 8192,\n",
      "    \"intermediate_size_mlp\": 16384,\n",
      "    \"max_position_embeddings\": 1048576,\n",
      "    \"model_type\": \"llama4_text\",\n",
      "    \"moe_layers\": [\n",
      "      1,\n",
      "      3,\n",
      "      5,\n",
      "      7,\n",
      "      9,\n",
      "      11,\n",
      "      13,\n",
      "      15,\n",
      "      17,\n",
      "      19,\n",
      "      21,\n",
      "      23,\n",
      "      25,\n",
      "      27,\n",
      "      29,\n",
      "      31,\n",
      "      33,\n",
      "      35,\n",
      "      37,\n",
      "      39,\n",
      "      41,\n",
      "      43,\n",
      "      45,\n",
      "      47\n",
      "    ],\n",
      "    \"no_rope_layers\": [\n",
      "      1,\n",
      "      1,\n",
      "      1,\n",
      "      0,\n",
      "      1,\n",
      "      1,\n",
      "      1,\n",
      "      0,\n",
      "      1,\n",
      "      1,\n",
      "      1,\n",
      "      0,\n",
      "      1,\n",
      "      1,\n",
      "      1,\n",
      "      0,\n",
      "      1,\n",
      "      1,\n",
      "      1,\n",
      "      0,\n",
      "      1,\n",
      "      1,\n",
      "      1,\n",
      "      0,\n",
      "      1,\n",
      "      1,\n",
      "      1,\n",
      "      0,\n",
      "      1,\n",
      "      1,\n",
      "      1,\n",
      "      0,\n",
      "      1,\n",
      "      1,\n",
      "      1,\n",
      "      0,\n",
      "      1,\n",
      "      1,\n",
      "      1,\n",
      "      0,\n",
      "      1,\n",
      "      1,\n",
      "      1,\n",
      "      0,\n",
      "      1,\n",
      "      1,\n",
      "      1,\n",
      "      0\n",
      "    ],\n",
      "    \"num_attention_heads\": 40,\n",
      "    \"num_experts_per_tok\": 1,\n",
      "    \"num_hidden_layers\": 48,\n",
      "    \"num_key_value_heads\": 8,\n",
      "    \"num_local_experts\": 128,\n",
      "    \"output_router_logits\": false,\n",
      "    \"pad_token_id\": 200018,\n",
      "    \"rms_norm_eps\": 1e-05,\n",
      "    \"rope_scaling\": null,\n",
      "    \"rope_theta\": 500000.0,\n",
      "    \"router_aux_loss_coef\": 0.001,\n",
      "    \"router_jitter_noise\": 0.0,\n",
      "    \"torch_dtype\": \"bfloat16\",\n",
      "    \"use_cache\": true,\n",
      "    \"use_qk_norm\": false,\n",
      "    \"vocab_size\": 202048\n",
      "  },\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.51.1\",\n",
      "  \"vision_config\": {\n",
      "    \"_attn_implementation_autoset\": true,\n",
      "    \"attention_dropout\": 0.0,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_size\": 1408,\n",
      "    \"image_size\": 336,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 5632,\n",
      "    \"model_type\": \"llama4_vision_model\",\n",
      "    \"multi_modal_projector_bias\": false,\n",
      "    \"norm_eps\": 1e-05,\n",
      "    \"num_attention_heads\": 16,\n",
      "    \"num_channels\": 3,\n",
      "    \"num_hidden_layers\": 34,\n",
      "    \"patch_size\": 14,\n",
      "    \"pixel_shuffle_ratio\": 0.5,\n",
      "    \"projector_dropout\": 0.0,\n",
      "    \"projector_input_dim\": 4096,\n",
      "    \"projector_output_dim\": 4096,\n",
      "    \"rope_theta\": 10000,\n",
      "    \"vision_feature_layer\": -1,\n",
      "    \"vision_feature_select_strategy\": \"default\",\n",
      "    \"vision_output_dim\": 4096\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ea70a86-3436-47af-a19f-f6a73926ca34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.llama4.configuration_llama4.Llama4Config'>\n"
     ]
    }
   ],
   "source": [
    "print(type(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f388e0e-5c42-4d47-95c4-5f6fcb96bb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202048\n"
     ]
    }
   ],
   "source": [
    "print(config.text_config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33297a9e-a56a-4d58-b8fa-1f69f4514082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
