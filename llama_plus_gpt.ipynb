{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593ee45f-5b08-4e65-9c23-2b7779fd8b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_BASE_MODEL = \"chatgpt-4o-latest\"\n",
    "\n",
    "SYSTEM_REVIEW_PROMPT = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"너는 1차 번역된 웹툰 대화를 검토하고 이를 수정하거나 아예 재생성하는 태스크를 수행할 거야. \\\n",
    "                    먼저 맥락을 이해하기 위해 한 회차의 모든 한국어 대화문이 주어지고, \\\n",
    "                    그 중에서 맨 마지막 두 줄에 [한글 대화]와 이 대화에 대응되는 [1차 영어 번역문]이 주어질 거야. \\\n",
    "                    먼저 [1차 영어 번역문]을 한글로 번역해서 [1차 한글 번역문]을 생성하고, [한글 대화]의 의미가 일치하는지 비교해.\\n\\\n",
    "                    만약 의미가 일치한다면 \\\n",
    "                    [한글 대화]에서 glossary에서 존재하는 표현은 없는지 검토하고, 만약 있다면 이를 반영해서 \\\n",
    "                    더 나은 [검토한 영어 번역문]을 생성해줘. 물론 [한글 대화]에 glossary에 존재하는 표현도 없고 기존 영어 번역문이 완벽하다면 그대로 생성해도 돼. \\\n",
    "                    하지만 만약 [1차 한글 번역문]과 [한글 대화]의 의미가 일치하지 않거나 정보의 양이 다르다면 \\\n",
    "                    [1차 영어 번역문]과 [1차 한글 번역문]은 무시하고 [한글 대화]에 대응하는 영어 번역문을 생성해.\\\n",
    "                    예를 들어 [한글 대화]가 '사과'인데 [1차 한글 번역문]이 '붉은 사과'라면 \\\n",
    "                    이는 [한글 대화]에 [1차 한글 번역문]의 일부만 제공된 상태이기 때문에 정보의 양이 다른 것으로 판단해. \\\n",
    "                    그렇기 때문에 [1차 한글 번역문]과 [1차 영어 번역문]은 무시하고 [한글 대화]만을 가지고 다시 번역하면 돼.\\n \\\n",
    "                    그리고 새롭게 생성한 영어 번역문은 <translate>로 시작하고 </translate>로 끝내, \\\n",
    "                    만약 추론이 필요하다면 <reasoning>으로 시작해서 추론 내용을 입력하고 </reasoning>으로 마무리해. \\\n",
    "                    추론할 때는 이 대사의 주어가 무엇인지도 생각해. 필요없으면 주어가 없어도 돼.\\\n",
    "                    ***important*** 그리고 출력에 다음 대사나 이전 대사의 내용을 추가하지말고, 주어진 [한글 대화]의 내용만으로 번역문을 구성해. \\\n",
    "                    쉽게 생각하면 너가 생성한 영어 번역문을 한글로 번역했을 때 주어진 [한글 대화]와 의미가 일치해야해\\n \\\n",
    "                    즉 정리하자면 출력 형태는 '<reasoning> ...추론 내용... </reasoning> <translate> 검토한 영어 번역문 </translate>' \\\n",
    "                    혹은 '<translate> 검토한 영어 번역문 </translate>' 가 될 거야\"\n",
    "                }\n",
    "            ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8cca8f-9327-4b31-ae44-5ca1ebe86e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bun.2/.cache/pypoetry/virtualenvs/poetry-env-eDEwtiIl-py3.10/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1820: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:00<00:00, 18343.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import re\n",
    "\n",
    "def instruct_structure(prompt):\n",
    "    input_text, output_text = prompt.split('### target')\n",
    "    input_text = input_text.replace('### glossaries', '### glossary').replace('\\n* ', '\\n• ')\n",
    "    input_text = re.sub(r\"\\[[^\\]]+\\] \", \"[UNK] \", input_text)\n",
    "    return input_text\n",
    "\n",
    "project_id = \"prod-ai-project\"\n",
    "client = bigquery.Client(project=project_id)\n",
    "sql = \"\"\"select series_id, episode_id, org_input_text, org_output_text, prompt \n",
    "        from webtoon_translation.structured_240820_ep_line\n",
    "        where data_split = 'romance_valid'\"\"\"\n",
    "df = client.query(sql).result().to_dataframe()\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "df['prompt'] = df['prompt'].progress_apply(lambda x: instruct_structure(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505deb8f-335f-4870-afad-c5b3757f3975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### glossary\n",
      "• 아벨 헤일론 (M): abel heylon\n",
      "• 아벨 (M): abel\n",
      "• 피오나 (F): fiona\n",
      "• 마법: magic / spell\n",
      "\n",
      "### source\n",
      "000\t[UNK] 북부 최전방 헤일론\n",
      "001\t[UNK] 여기가 헤일론 공작 성….\n",
      "002\t[UNK] 엄청난 위압감이야…\n",
      "003\t[UNK] 나는 결국 가족에게 떠밀려 무자비한 공작이 다스린다는 북부 최전방에 왔다.\n",
      "004\t[UNK] 딱 봐도 마왕성 같은 게 사람 엄청 굴릴 것 같다.\n",
      "005\t[UNK] 내 무덤을 내가 팠지...\n",
      "006\t[UNK] 이쪽으로.\n",
      "007\t[UNK] 문을 열어라.\n",
      "008\t[UNK] 문이, 엄청 커…!!\n",
      "009\t[UNK] 북부의 공작, 아벨 헤일론\n",
      "010\t[UNK] 너 나름대로는 각오했겠지. 하지만…\n",
      "011\t[UNK] 너 같은 어린애는 여기에 필요 없다.\n",
      "012\t[UNK] 집으로 돌아가도록.\n",
      "013\t[UNK] 쓸모없는 자에게 투자할 시간은 없다 이건가.\n",
      "014\t[UNK] 아벨은 모르겠지만, 지금의 나는 마땅히 돌아갈 곳도 없어.\n",
      "015\t[UNK] 원작 속의, 자신의 마법적 재능을 모르던 피오나는-\n",
      "016\t[UNK] 이렇게 그린 가문에서도 헤일론에서도 쫓겨난다.\n",
      "017\t[UNK] 그리고 이때 세상에 버림받은 상처가\n",
      "018\t[UNK] 후에 피오나가 악역이 되는 결정적인 계기가 된다.\n",
      "019\t[UNK] 하지만 지금의 나는 알고 있어.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df['prompt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed29f515-2d79-45a7-96f2-b07412c09689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   hangle                          first_translate\n",
      "0            …너에게 미움받는 게,                         I’m terrified...\n",
      "1                 너무 무서워.                     ...of you hating me.\n",
      "2                    시그렌.                                 siegren.\n",
      "3              잠깐 옆으로 갈게.       let’s go over there for  a second.\n",
      "4                     저기,  can you lean forward just a little bit?\n",
      "..                    ...                                      ...\n",
      "92                     왜?                                     why?\n",
      "93             어머, 모르셨어요?             oh dear, you hadn’t noticed?\n",
      "94  아가씨 목에 벌레 물린 자국이 있어요.    there’s a bug bite mark on your neck.\n",
      "95                     시,                            s-siegren...!\n",
      "96                  시그레엔!                                         \n",
      "\n",
      "[97 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#1차 초벌 번역된 결과물이 번역전 원본의 문장 개수와 같은지 체크\n",
    "#같지 않다면 \n",
    "import pandas as pd\n",
    "for data_idx in range(74):\n",
    "    llama_df = pd.read_csv(f\"data/llama_result/llama_vllm_{data_idx}.csv\")\n",
    "    data = df['prompt'][data_idx].split('### source')[1].strip()\n",
    "    section = [clean_text(d) for d in data.split('\\n')]\n",
    "    if len(llama_df) < len(section):\n",
    "        # print(data_idx, len(llama_df), len(section))\n",
    "        # print(section)\n",
    "        add_num = len(section) - len(llama_df)\n",
    "        for i in range(len(llama_df), len(llama_df)+add_num):\n",
    "            llama_df.loc[i] = [section[i], '']\n",
    "        print(llama_df)\n",
    "    elif len(llama_df) > len(section): # 만약 원데이터보다 더 많은 번역을 했을 경우\n",
    "        print('error occur')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e66d5cf2-bfeb-4cba-8f5d-8965df263fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1차 한글 번역문] 북쪽 최전방 헤일론 영토  \n",
      "\n",
      "<reasoning>  \n",
      "'북부 최전방 헤일론'은 특정 지역명을 가리키는 표현이다. 'the northernmost region'은 '가장 북쪽 지역'이라는 의미로 해석될 수 있지만, '최전방'이라는 뉘앙스를 충분히 전달하지 못한다. '헤일론'은 고유명사이므로 'Haelion'으로 유지해야 하며, '최전방'을 강조하기 위해 'frontline'이라는 단어를 사용하는 것이 적절하다.  \n",
      "</reasoning>  \n",
      "\n",
      "<translate>  \n",
      "Haelion, the northern frontline  \n",
      "</translate>  \n",
      "[1차 한글 번역문] 여기는 하우스 헤일리온의 성...!  \n",
      "[한글 대화] 여기가 헤일론 공작 성….  \n",
      "\n",
      "<reasoning>  \n",
      "\"House Haelion\"이라는 표현은 \"헤일론 공작 성\"을 번역한 것으로 보이지만, \"공작 성\"은 \"Duke's castle\"로 번역하는 것이 더 자연스럽다. 또한, \"여기가\"는 \"This is\"보다는 \"So this is\"가 더 적절할 수 있다.  \n",
      "</reasoning>  \n",
      "\n",
      "<translate>  \n",
      "So this is Duke Haelion's castle...  \n",
      "</translate>  \n",
      "[1차 한글 번역문] 너무 위압적이야...  \n",
      "[한글 대화]와 [1차 한글 번역문]의 의미가 유사하므로, 기존 번역을 유지할 수 있음.  \n",
      "\n",
      "<translate>It's so overwhelming...</translate>\n",
      "[1차 한글 번역문] 나는 가족에게 떠밀려 이 먼 북쪽까지 왔다. 무자비하기로 유명한 헤일론 공작의 통치 아래 살아야 한다.  \n",
      "\n",
      "[비교]  \n",
      "- [1차 한글 번역문]은 원문의 의미를 대체로 반영하고 있지만, \"북부 최전방\"이라는 표현이 \"이 먼 북쪽\"으로 번역되면서 원문의 뉘앙스가 약간 달라졌다.  \n",
      "- \"무자비한 공작이 다스린다는\" 부분이 \"무자비하기로 유명한 헤일론 공작의 통치 아래 살아야 한다\"로 번역되었는데, 원문의 \"다스린다는\"은 단순한 사실 서술이지만, 1차 번역문은 \"살아야 한다\"라는 의미를 추가하여 다소 다르게 해석되었다.  \n",
      "- \"결국\"이라는 단어가 빠져 있어 원문의 뉘앙스를 완전히 반영하지 못했다.  \n",
      "\n",
      "[수정 방향]  \n",
      "- \"북부 최전방\"을 보다 정확하게 \"the northernmost front\"로 번역.  \n",
      "- \"결국\"을 반영하여 문장의 흐름을 자연스럽게 조정.  \n",
      "- \"다스린다는\"을 보다 직설적으로 표현.  \n",
      "\n",
      "<translate>  \n",
      "In the end, I was forced by my family to come to the northernmost front, ruled by a ruthless duke.  \n",
      "</translate>  \n",
      "[1차 한글 번역문] 저곳은 마왕의 소굴처럼 보인다! 거기서는 사람들을 끔찍하게 대하겠지.  \n",
      "<reasoning>  \n",
      "[1차 한글 번역문]은 [한글 대화]의 의미를 정확히 반영하지 못하고 있다.  \n",
      "1. \"딱 봐도\"는 \"at a glance\" 또는 \"just by looking\" 등의 표현이 적절하다.  \n",
      "2. \"마왕성 같은 게\"는 \"like a demon king's castle\"로 번역하는 것이 더 자연스럽다.  \n",
      "3. \"사람 엄청 굴릴 것 같다\"는 \"seems like it would work people really hard\" 정도로 번역할 수 있다.  \n",
      "4. [1차 영어 번역문]에서는 \"treat people terribly\"라고 번역했는데, 이는 \"사람을 가혹하게 대한다\"는 의미로, 원문의 \"사람 엄청 굴릴 것 같다\"와는 차이가 있다.  \n",
      "따라서, 원문의 의미를 반영하여 새롭게 번역해야 한다.  \n",
      "</reasoning>  \n",
      "<translate>  \n",
      "It looks just like a demon king's castle. They must work people to the bone there.  \n",
      "</translate>  \n",
      "[1차 한글 번역문] 내가 내 무덤을 판 걸까?  \n",
      "\n",
      "[한글 대화]와 [1차 한글 번역문]을 비교했을 때, 원문의 확신하는 어조(\"내 무덤을 내가 팠지...\")와 1차 번역문의 의문형(\"내가 내 무덤을 판 걸까?\")이 다르다. 따라서 [1차 영어 번역문]을 무시하고 새롭게 번역해야 한다.  \n",
      "\n",
      "<translate>I've dug my own grave...</translate>\n",
      "<translate>This way.</translate>\n",
      "<translate>Open the door.</translate>\n",
      "<translate>Th-The gate is enormous...!!!</translate>\n",
      "<translate>Duke of the North, Abel Hailon.</translate>\n",
      "<1차 한글 번역문> 나는 네가 준비되었을 거라고 확신해.  \n",
      "<reasoning>  \n",
      "\"너 나름대로는 각오했겠지.\"는 상대방이 나름대로 마음의 준비를 했을 것이라고 추측하는 표현이다.  \n",
      "하지만 \"I’m sure you’re prepared,\"는 확신의 뉘앙스를 가지며, 원문의 \"하지만…\" 부분이 빠져 있다.  \n",
      "이를 반영하여 더 자연스럽게 수정해야 한다.  \n",
      "</reasoning>  \n",
      "<translate> You must have braced yourself in your own way. But… </translate>\n",
      "[1차 한글 번역문] 하지만 우리는 여기서 너처럼 어린 아이는 필요하지 않아.  \n",
      "[한글 대화]와 의미가 일치하므로, glossary를 반영하여 검토한 영어 번역문을 생성함.  \n",
      "\n",
      "<translate>We have no need for a kid like you here.</translate>\n",
      "[1차 한글 번역문] 집으로 돌아가.  \n",
      "[한글 대화]와 [1차 한글 번역문]을 비교했을 때, 원문의 \"집으로 돌아가도록.\"이 더 명령조이면서도 격식을 갖춘 표현이다.  \n",
      "따라서 이를 반영하여 더 적절한 영어 번역문을 생성해야 한다.  \n",
      "\n",
      "<translate>Return home.</translate>\n",
      "[1차 한글 번역문] 그 말은 내가 쓸모없어서 시간 낭비하고 싶지 않다는 뜻인가?  \n",
      "[한글 대화]와 비교했을 때 의미는 대체로 일치하지만, 원문의 어조가 더 건조하고 간결한 반면, 1차 번역문은 주어(he)와 감정적인 해석이 추가되었다. 따라서 원문의 느낌을 살려 다시 번역하는 것이 적절하다.  \n",
      "\n",
      "<translate> So he has no time to waste on someone useless. </translate>\n",
      "[1차 한글 번역문] 아벨은 거의 모르겠지만, 지금 나는 갈 곳조차 없어.  \n",
      "[한글 대화]와 비교했을 때 의미가 거의 일치하지만, \"little does abel know\"는 \"아벨은 거의 모르지\"라는 의미로, 원문의 \"아벨은 모르겠지만\"과는 뉘앙스 차이가 있음. 따라서 이를 반영하여 수정함.  \n",
      "\n",
      "<translate>Abel may not know, but right now, I have nowhere to go.</translate>\n",
      "<translate>In the original story, Fiona, who was unaware of her magical talent,</translate>\n",
      "<reasoning> \n",
      "1차 영어 번역문에서 \"house haelion\"이라는 표현이 사용되었는데, 이는 \"헤일론 가문\"을 의미하려는 것으로 보인다. 하지만 \"house Haelion\"보다는 \"the Haelion family\" 또는 \"Haelion\" 단독으로 쓰는 것이 더 자연스럽다.  \n",
      "또한, \"그린 가문\"과 \"헤일론\"에서 쫓겨났다는 의미를 명확히 전달하기 위해 \"both the Green family and Haelion\"을 사용하는 것이 적절하다.  \n",
      "</reasoning>  \n",
      "<translate> She was chased out from both the Green family and Haelion. </translate>\n",
      "[1차 한글 번역문] 그리고 그 순간, 그녀는 주변 모든 사람들에게 버림받았다고 느꼈다.  \n",
      "\n",
      "<reasoning>  \n",
      "[한글 대화]는 \"그리고 이때 세상에 버림받은 상처가\"로, 특정한 감정보다는 '상처'라는 개념에 초점이 맞춰져 있다.  \n",
      "반면 [1차 한글 번역문]은 \"그녀는 주변 모든 사람들에게 버림받았다고 느꼈다.\"로 번역되어 있어, '상처'보다는 '느낌'에 초점이 맞춰져 있다.  \n",
      "즉, 원문의 핵심 개념인 '상처'가 제대로 반영되지 않았으므로, 이를 고려하여 다시 번역해야 한다.  \n",
      "</reasoning>  \n",
      "\n",
      "<translate> And at that moment, the wound of being abandoned by the world </translate>\n",
      "[1차 한글 번역문] 피오나는 악역이 되기로 결심했다.  \n",
      "<reasoning>  \n",
      "[한글 대화]에서는 \"결정적인 계기\"가 된다고 말하고 있지만, [1차 영어 번역문]에서는 피오나가 스스로 \"결심했다\"고 번역되어 의미가 다르다.  \n",
      "\"결정적인 계기\"는 어떤 사건이 피오나가 악역이 되는 데 중요한 영향을 미쳤다는 의미이므로, 이를 반영하여 다시 번역해야 한다.  \n",
      "</reasoning>  \n",
      "<translate> This became the decisive turning point that led Fiona to become a villainess. </translate>\n",
      "<reasoning>  \n",
      "[1차 영어 번역문]은 \"하지만 지금의 나는 알고 있어.\"라는 [한글 대화]보다 더 많은 정보를 포함하고 있다.  \n",
      "특히, \"I already know about my abilities. I can use them to prove myself.\" 등의 내용은 원문에 없는 추가적인 정보이다.  \n",
      "따라서 [1차 영어 번역문]을 무시하고, [한글 대화]만을 기반으로 새로운 번역문을 생성해야 한다.  \n",
      "</reasoning>  \n",
      "\n",
      "<translate>  \n",
      "But now, I know.  \n",
      "</translate>  \n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "openai_client = OpenAI(\n",
    "    api_key='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')\n",
    "\n",
    "def extract_translation(text):\n",
    "    match = re.search(r'<translate>(.*?)</translate>', text, re.DOTALL)\n",
    "    return match.group(1).strip() if match else None\n",
    "\n",
    "def clean_text(text):\n",
    "    return re.sub(r'^\\d+\\s+\\[UNK\\]\\s+', '', text)\n",
    "\n",
    "\n",
    "for data_idx in range(74):\n",
    "    llama_df = pd.read_csv(f\"data/llama_result/llama_vllm_{data_idx}.csv\")\n",
    "    data = df['prompt'][data_idx].split('### source')[1].strip()\n",
    "    section = [clean_text(d) for d in data.split('\\n')]\n",
    "    \n",
    "    if len(llama_df) < len(section):\n",
    "        # print(data_idx, len(llama_df), len(section))\n",
    "        # print(section)\n",
    "        add_num = len(section) - len(llama_df)\n",
    "        for i in range(len(llama_df), len(llama_df)+add_num):\n",
    "            llama_df.loc[i] = [section[i], '']\n",
    "        print(llama_df)\n",
    "    elif len(llama_df) > len(section): # 만약 원데이터보다 더 많은 번역을 했을 경우\n",
    "        print('error occur')\n",
    "\n",
    "    section = '\\n'.join(section)\n",
    "    #한 회차에 대한 모든 초벌 번역에 대해서 검수\n",
    "    review_li = []\n",
    "    for i in range(len(llama_df)):\n",
    "        hangle = llama_df['hangle'][i]\n",
    "        first_translate = llama_df['first_translate'][i]\n",
    "        review_text = f\"{section}\\n\\n### review\\n[한글 대화] {hangle}\\n[1차 영어 번역문] {first_translate}\\n\\n\"\n",
    "        review_completion = openai_client.beta.chat.completions.parse(\n",
    "            model= GPT_BASE_MODEL,\n",
    "            messages = [\n",
    "                SYSTEM_REVIEW_PROMPT,\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\" : [{\"type\" : \"text\",\n",
    "                                  \"text\" : review_text}],\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            top_p=0.8\n",
    "        )\n",
    "        review = review_completion.choices[0].message.content\n",
    "        print(review)\n",
    "        review_li.append(extract_translation(review))\n",
    "    hangles = llama_df['hangle'].tolist()\n",
    "    first_translates = llama_df['first_translate'].tolist()\n",
    "    final_df = pd.DataFrame({'hangle':hangles, 'first_translate':first_translates, 'review':review_li})\n",
    "    final_df.to_csv(f'data/llama_result/llama_result_review_{data_idx}.csv', index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e788cd7-bec2-4a4a-af1b-ad2a4d846f75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
