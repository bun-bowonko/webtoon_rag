{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ade6217-bec1-44a2-ba65-610281b376e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import bs4\n",
    "import ssl\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fec720e-64b7-4755-b8ac-97b2c7fb219b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "file_path = \"./data/idiom_dict.txt\"\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "lines = [line.strip() for line in lines]\n",
    "\n",
    "docs = [Document(page_content=f\"{line}\") for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a2377b4-30f8-4aac-ac1a-755f520a73c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22138\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5221f41-2916-4b5a-ab6d-1e9724714ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가슴이 뜨겁다 > Have a passionate heart\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe1d6b2-eecc-419e-9929-dfe040dfb5e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_63326/3629734522.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")\n",
      "/home/bun.2/.cache/pypoetry/virtualenvs/poetry-env-eDEwtiIl-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a6178d-8302-41c7-8d61-d8def0deba3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐시된 벡터 로드...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "faiss_index_path = \"./embed_vector/multilingual-e5-large\"\n",
    "if os.path.exists(faiss_index_path):\n",
    "    print(\"캐시된 벡터 로드...\")\n",
    "    vectorstore = FAISS.load_local(faiss_index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "else:\n",
    "    print(\"새로운 벡터를 생성하고 저장...\")\n",
    "    vectorstore = FAISS.from_documents(documents=docs, embedding=embeddings)\n",
    "    vectorstore.save_local(faiss_index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9143b32e-123e-4c50-8bbb-94cee423ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ FAISS 인덱스를 GPU로 변환 (공통 적용)\n",
    "import faiss\n",
    "try:\n",
    "    # FAISS 인덱스를 GPU로 변환\n",
    "    res = faiss.StandardGpuResources()\n",
    "    gpu_index = faiss.index_cpu_to_gpu(res, 0, vectorstore.index)\n",
    "    vectorstore.index = gpu_index\n",
    "    print(\"GPU로 성공적으로 인덱스를 변환했습니다!\")\n",
    "    print(type(gpu_index))\n",
    "except faiss.FaissException as e:\n",
    "    print(f\"FAISS 에러 발생: {e}\")\n",
    "    print(\"GPU 메모리가 부족하거나, 다른 이유로 변환에 실패했습니다.\")\n",
    "\n",
    "if isinstance(vectorstore.index, faiss.GpuIndex):  # GPU 인덱스이면\n",
    "    print(\"🚀 FAISS 인덱스가 GPU에서 실행 중입니다!\")\n",
    "else:\n",
    "    print(\"💻 FAISS 인덱스가 CPU에서 실행 중입니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37d7e7e2-3f6f-4593-bdce-c10c114011b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type='similarity', search_kwargs={'k':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc51866f-fd3b-49bf-9421-b8e04d9b1242",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['FAISS', 'HuggingFaceEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7fab11317970> search_kwargs={'k': 10}\n"
     ]
    }
   ],
   "source": [
    "print(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dcf315b-be4b-4716-88a3-0487f6bc1430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"용어집을 반영해서 한국어를 영어로 번역해줘. \\\n",
    "첫 번째 번역은 <translate_start1>으로 시작하고 <translate_end1>로 끝내줘. \\\n",
    "그 다음 틀린 부분이 있나 검토하고 두 번 째 번역은 <translate_start2>로 시작하고 <translate_end2>로 끝내줘. \\\n",
    "마지막으로 번역한 문장을 다시 한국어로 번역한 후에, 주어진 한국어({question})와 일치하는지 검토해. \\\n",
    "일치하면 두 번 째 번역과 동일하게 번역하고, 일치하지 않으면 한국어와 동일한 의미를 가진 영어로 다시 번역해줘. \\\n",
    "마지막 영어 번역은 <translate_start3>로 시작하고 <translate_end3>로 끝내줘. \\\n",
    "용어집에 유사한 표현이 있으면 해당 영어 표현을 꼭 참고해서 번역해줘. \\\n",
    "용어집 : {context}\\n\\n한국어 : {question}\"\n",
    "\n",
    "# template = \"용어집을 반영해서 한국어를 영어로 번역해줘. \\\n",
    "# 번역은 <translate_start>로 시작하고 <translate_end>로 끝내줘. \\\n",
    "# 용어집에 유사한 표현이 있으면 해당 영어 표현을 꼭 참고해서 번역해줘. \\\n",
    "# 용어집 : {context}\\n\\n한국어 : {question}\"\n",
    "input_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feae9f61-6491-4146-a19f-bdd2475fe5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_617727/2261560295.py:1: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model='qwen:latest', temperature=0)\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOllama(model='qwen:latest', temperature=0)\n",
    "#llm = ChatOllama(model='llama3:70b', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b57de46-5c53-4fba-ad96-174bcc76261e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6413065e-c44d-4496-9df5-8a2ac81d5045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_info(docs,question):\n",
    "    return {\"context\":'\\n\\n'.join(doc.page_content for doc in docs), \"question\":question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60018cd2-4f9f-41ca-824d-0766d761fc80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_and_merge(question):\n",
    "    docs = retriever.invoke(question) #retriever로 문서 가져오고\n",
    "    return merge_info(docs, question) #context와 question 포함한 딕셔너리 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b067ba06-849f-4b17-9d15-fb9498c3deb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<translation_start1>\n",
      "If you just get through today, no matter what happens from now on, you will be safe.\n",
      "<translation_end1>\n",
      "\n",
      "<translation_start2>\n",
      "If you just make it through today, no matter what happens from now on, you'll be completely safe.\n",
      "<translation_end2>\n",
      "\n",
      "오늘만 넘기면 이제 목에 칼이 들어와도 넌 안전할 거야. -> If you just make it through today, no matter what happens from now on, you'll be completely safe.\n",
      "\n",
      "<translation_start3>\n",
      "If you just make it through today, no matter what happens from now on, you'll be completely safe.\n",
      "<translation_end3> \n",
      "\n",
      "두 번째 번역과 세 번째 번역이 일치하며, 주어진 한국어 문장의 의미와 동일합니다.\n",
      "걸린 시간 :  111.6017119884491\n"
     ]
    }
   ],
   "source": [
    "#chain_level_3 = {'question' : RunnablePassthrough(), 'context':retriever | merge_info} | input_prompt | llm | output_parser\n",
    "chain_level_3 = RunnablePassthrough() | retrieve_and_merge | input_prompt | llm | output_parser\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "print(chain_level_3.invoke('오늘만 넘기면 이제 목에 칼이 들어와도 넌 안전할 거야.'))\n",
    "print(\"걸린 시간 : \",time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c525a315-42c6-4b74-8974-fe64f5560922",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='호랑이에게 물려 가도 정신만 차리면 산다 > Stay calm in danger'\n",
      "page_content='목에 칼이 들어와도 > No matter what happens'\n",
      "page_content='내 턱에 칼이 들어와도 > No matter what happens'\n",
      "page_content='털끝 하나 다치지 않다 > Stay completely safe'\n",
      "page_content='호랑이굴에 들어가도 정신만 차리면 산다 > Stay calm even in danger'\n",
      "page_content='칼을 뽑았으면 무라도 썰어야 한다 > If you start, see it through.'\n",
      "page_content='범에게 물려 가도 정신만 차리면 산다 > Stay calm in crisis'\n",
      "page_content='털 끝 하나 상하지 않다 > Be completely safe'\n",
      "page_content='허리에 칼을 차다 > Be overly confident'\n",
      "page_content='털끝 하나 다치지 않게 하다 > Keep completely safe'\n",
      "page_content='칼끝이 서다 > Be on edge'\n",
      "page_content='칼을 뽑았으면 무라도 잘라라 > Follow through once you've started'\n",
      "page_content='얕은 내도 깊게 건너라 > Be cautious even in simple matters.'\n",
      "page_content='호랑이가 물어가도 정신만 차리면 산다 > Stay calm in crisis'\n",
      "page_content='호랑이에게 물려가도 정신만 차리면 산다 > Stay calm in a crisis'\n",
      "page_content='호랑이 굴에 들어가도 정신만 차리면 산다 > Stay calm in crisis'\n",
      "page_content='지키는 것이 곧 얻는 것이다 > Protecting what you have is valuable'\n",
      "page_content='칼 끝에 주워 먹다 > Barely survive'\n",
      "page_content='털 끝 하나 다치게 하지 않겠다 > Will protect completely.'\n",
      "page_content='서둘러야 할 시기다 > Now is the crucial time'\n"
     ]
    }
   ],
   "source": [
    "test_docs = retriever.invoke('오늘만 넘기면 이제 목에 칼이 들어와도 넌 안전할 거야.')\n",
    "for d in test_docs:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53b112-463d-4a38-b5f6-a44fe0c5390d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-poetry-env-qdleyyui-py3.10",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
