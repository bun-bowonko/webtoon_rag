{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ade6217-bec1-44a2-ba65-610281b376e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import bs4\n",
    "import ssl\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fec720e-64b7-4755-b8ac-97b2c7fb219b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "file_path = \"./data/idiom_dict.txt\"\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "lines = [line.strip() for line in lines]\n",
    "\n",
    "docs = [Document(page_content=f\"{line}\") for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a2377b4-30f8-4aac-ac1a-755f520a73c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22138\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5221f41-2916-4b5a-ab6d-1e9724714ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°€ìŠ´ì´ ëœ¨ê²ë‹¤ > Have a passionate heart\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe1d6b2-eecc-419e-9929-dfe040dfb5e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_63326/3629734522.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")\n",
      "/home/bun.2/.cache/pypoetry/virtualenvs/poetry-env-eDEwtiIl-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a6178d-8302-41c7-8d61-d8def0deba3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºì‹œëœ ë²¡í„° ë¡œë“œ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "faiss_index_path = \"./embed_vector/multilingual-e5-large\"\n",
    "if os.path.exists(faiss_index_path):\n",
    "    print(\"ìºì‹œëœ ë²¡í„° ë¡œë“œ...\")\n",
    "    vectorstore = FAISS.load_local(faiss_index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "else:\n",
    "    print(\"ìƒˆë¡œìš´ ë²¡í„°ë¥¼ ìƒì„±í•˜ê³  ì €ì¥...\")\n",
    "    vectorstore = FAISS.from_documents(documents=docs, embedding=embeddings)\n",
    "    vectorstore.save_local(faiss_index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9143b32e-123e-4c50-8bbb-94cee423ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… FAISS ì¸ë±ìŠ¤ë¥¼ GPUë¡œ ë³€í™˜ (ê³µí†µ ì ìš©)\n",
    "import faiss\n",
    "try:\n",
    "    # FAISS ì¸ë±ìŠ¤ë¥¼ GPUë¡œ ë³€í™˜\n",
    "    res = faiss.StandardGpuResources()\n",
    "    gpu_index = faiss.index_cpu_to_gpu(res, 0, vectorstore.index)\n",
    "    vectorstore.index = gpu_index\n",
    "    print(\"GPUë¡œ ì„±ê³µì ìœ¼ë¡œ ì¸ë±ìŠ¤ë¥¼ ë³€í™˜í–ˆìŠµë‹ˆë‹¤!\")\n",
    "    print(type(gpu_index))\n",
    "except faiss.FaissException as e:\n",
    "    print(f\"FAISS ì—ëŸ¬ ë°œìƒ: {e}\")\n",
    "    print(\"GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•˜ê±°ë‚˜, ë‹¤ë¥¸ ì´ìœ ë¡œ ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "if isinstance(vectorstore.index, faiss.GpuIndex):  # GPU ì¸ë±ìŠ¤ì´ë©´\n",
    "    print(\"ğŸš€ FAISS ì¸ë±ìŠ¤ê°€ GPUì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"ğŸ’» FAISS ì¸ë±ìŠ¤ê°€ CPUì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37d7e7e2-3f6f-4593-bdce-c10c114011b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type='similarity', search_kwargs={'k':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc51866f-fd3b-49bf-9421-b8e04d9b1242",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['FAISS', 'HuggingFaceEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7fab11317970> search_kwargs={'k': 10}\n"
     ]
    }
   ],
   "source": [
    "print(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dcf315b-be4b-4716-88a3-0487f6bc1430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"ìš©ì–´ì§‘ì„ ë°˜ì˜í•´ì„œ í•œêµ­ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•´ì¤˜. \\\n",
    "ì²« ë²ˆì§¸ ë²ˆì—­ì€ <translate_start1>ìœ¼ë¡œ ì‹œì‘í•˜ê³  <translate_end1>ë¡œ ëë‚´ì¤˜. \\\n",
    "ê·¸ ë‹¤ìŒ í‹€ë¦° ë¶€ë¶„ì´ ìˆë‚˜ ê²€í† í•˜ê³  ë‘ ë²ˆ ì§¸ ë²ˆì—­ì€ <translate_start2>ë¡œ ì‹œì‘í•˜ê³  <translate_end2>ë¡œ ëë‚´ì¤˜. \\\n",
    "ë§ˆì§€ë§‰ìœ¼ë¡œ ë²ˆì—­í•œ ë¬¸ì¥ì„ ë‹¤ì‹œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•œ í›„ì—, ì£¼ì–´ì§„ í•œêµ­ì–´({question})ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€í† í•´. \\\n",
    "ì¼ì¹˜í•˜ë©´ ë‘ ë²ˆ ì§¸ ë²ˆì—­ê³¼ ë™ì¼í•˜ê²Œ ë²ˆì—­í•˜ê³ , ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ í•œêµ­ì–´ì™€ ë™ì¼í•œ ì˜ë¯¸ë¥¼ ê°€ì§„ ì˜ì–´ë¡œ ë‹¤ì‹œ ë²ˆì—­í•´ì¤˜. \\\n",
    "ë§ˆì§€ë§‰ ì˜ì–´ ë²ˆì—­ì€ <translate_start3>ë¡œ ì‹œì‘í•˜ê³  <translate_end3>ë¡œ ëë‚´ì¤˜. \\\n",
    "ìš©ì–´ì§‘ì— ìœ ì‚¬í•œ í‘œí˜„ì´ ìˆìœ¼ë©´ í•´ë‹¹ ì˜ì–´ í‘œí˜„ì„ ê¼­ ì°¸ê³ í•´ì„œ ë²ˆì—­í•´ì¤˜. \\\n",
    "ìš©ì–´ì§‘ : {context}\\n\\ní•œêµ­ì–´ : {question}\"\n",
    "\n",
    "# template = \"ìš©ì–´ì§‘ì„ ë°˜ì˜í•´ì„œ í•œêµ­ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•´ì¤˜. \\\n",
    "# ë²ˆì—­ì€ <translate_start>ë¡œ ì‹œì‘í•˜ê³  <translate_end>ë¡œ ëë‚´ì¤˜. \\\n",
    "# ìš©ì–´ì§‘ì— ìœ ì‚¬í•œ í‘œí˜„ì´ ìˆìœ¼ë©´ í•´ë‹¹ ì˜ì–´ í‘œí˜„ì„ ê¼­ ì°¸ê³ í•´ì„œ ë²ˆì—­í•´ì¤˜. \\\n",
    "# ìš©ì–´ì§‘ : {context}\\n\\ní•œêµ­ì–´ : {question}\"\n",
    "input_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feae9f61-6491-4146-a19f-bdd2475fe5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_617727/2261560295.py:1: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model='qwen:latest', temperature=0)\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOllama(model='qwen:latest', temperature=0)\n",
    "#llm = ChatOllama(model='llama3:70b', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b57de46-5c53-4fba-ad96-174bcc76261e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6413065e-c44d-4496-9df5-8a2ac81d5045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_info(docs,question):\n",
    "    return {\"context\":'\\n\\n'.join(doc.page_content for doc in docs), \"question\":question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60018cd2-4f9f-41ca-824d-0766d761fc80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_and_merge(question):\n",
    "    docs = retriever.invoke(question) #retrieverë¡œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê³ \n",
    "    return merge_info(docs, question) #contextì™€ question í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b067ba06-849f-4b17-9d15-fb9498c3deb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<translation_start1>\n",
      "If you just get through today, no matter what happens from now on, you will be safe.\n",
      "<translation_end1>\n",
      "\n",
      "<translation_start2>\n",
      "If you just make it through today, no matter what happens from now on, you'll be completely safe.\n",
      "<translation_end2>\n",
      "\n",
      "ì˜¤ëŠ˜ë§Œ ë„˜ê¸°ë©´ ì´ì œ ëª©ì— ì¹¼ì´ ë“¤ì–´ì™€ë„ ë„Œ ì•ˆì „í•  ê±°ì•¼. -> If you just make it through today, no matter what happens from now on, you'll be completely safe.\n",
      "\n",
      "<translation_start3>\n",
      "If you just make it through today, no matter what happens from now on, you'll be completely safe.\n",
      "<translation_end3> \n",
      "\n",
      "ë‘ ë²ˆì§¸ ë²ˆì—­ê³¼ ì„¸ ë²ˆì§¸ ë²ˆì—­ì´ ì¼ì¹˜í•˜ë©°, ì£¼ì–´ì§„ í•œêµ­ì–´ ë¬¸ì¥ì˜ ì˜ë¯¸ì™€ ë™ì¼í•©ë‹ˆë‹¤.\n",
      "ê±¸ë¦° ì‹œê°„ :  111.6017119884491\n"
     ]
    }
   ],
   "source": [
    "#chain_level_3 = {'question' : RunnablePassthrough(), 'context':retriever | merge_info} | input_prompt | llm | output_parser\n",
    "chain_level_3 = RunnablePassthrough() | retrieve_and_merge | input_prompt | llm | output_parser\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "print(chain_level_3.invoke('ì˜¤ëŠ˜ë§Œ ë„˜ê¸°ë©´ ì´ì œ ëª©ì— ì¹¼ì´ ë“¤ì–´ì™€ë„ ë„Œ ì•ˆì „í•  ê±°ì•¼.'))\n",
    "print(\"ê±¸ë¦° ì‹œê°„ : \",time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c525a315-42c6-4b74-8974-fe64f5560922",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='í˜¸ë‘ì´ì—ê²Œ ë¬¼ë ¤ ê°€ë„ ì •ì‹ ë§Œ ì°¨ë¦¬ë©´ ì‚°ë‹¤ > Stay calm in danger'\n",
      "page_content='ëª©ì— ì¹¼ì´ ë“¤ì–´ì™€ë„ > No matter what happens'\n",
      "page_content='ë‚´ í„±ì— ì¹¼ì´ ë“¤ì–´ì™€ë„ > No matter what happens'\n",
      "page_content='í„¸ë í•˜ë‚˜ ë‹¤ì¹˜ì§€ ì•Šë‹¤ > Stay completely safe'\n",
      "page_content='í˜¸ë‘ì´êµ´ì— ë“¤ì–´ê°€ë„ ì •ì‹ ë§Œ ì°¨ë¦¬ë©´ ì‚°ë‹¤ > Stay calm even in danger'\n",
      "page_content='ì¹¼ì„ ë½‘ì•˜ìœ¼ë©´ ë¬´ë¼ë„ ì°ì–´ì•¼ í•œë‹¤ > If you start, see it through.'\n",
      "page_content='ë²”ì—ê²Œ ë¬¼ë ¤ ê°€ë„ ì •ì‹ ë§Œ ì°¨ë¦¬ë©´ ì‚°ë‹¤ > Stay calm in crisis'\n",
      "page_content='í„¸ ë í•˜ë‚˜ ìƒí•˜ì§€ ì•Šë‹¤ > Be completely safe'\n",
      "page_content='í—ˆë¦¬ì— ì¹¼ì„ ì°¨ë‹¤ > Be overly confident'\n",
      "page_content='í„¸ë í•˜ë‚˜ ë‹¤ì¹˜ì§€ ì•Šê²Œ í•˜ë‹¤ > Keep completely safe'\n",
      "page_content='ì¹¼ëì´ ì„œë‹¤ > Be on edge'\n",
      "page_content='ì¹¼ì„ ë½‘ì•˜ìœ¼ë©´ ë¬´ë¼ë„ ì˜ë¼ë¼ > Follow through once you've started'\n",
      "page_content='ì–•ì€ ë‚´ë„ ê¹Šê²Œ ê±´ë„ˆë¼ > Be cautious even in simple matters.'\n",
      "page_content='í˜¸ë‘ì´ê°€ ë¬¼ì–´ê°€ë„ ì •ì‹ ë§Œ ì°¨ë¦¬ë©´ ì‚°ë‹¤ > Stay calm in crisis'\n",
      "page_content='í˜¸ë‘ì´ì—ê²Œ ë¬¼ë ¤ê°€ë„ ì •ì‹ ë§Œ ì°¨ë¦¬ë©´ ì‚°ë‹¤ > Stay calm in a crisis'\n",
      "page_content='í˜¸ë‘ì´ êµ´ì— ë“¤ì–´ê°€ë„ ì •ì‹ ë§Œ ì°¨ë¦¬ë©´ ì‚°ë‹¤ > Stay calm in crisis'\n",
      "page_content='ì§€í‚¤ëŠ” ê²ƒì´ ê³§ ì–»ëŠ” ê²ƒì´ë‹¤ > Protecting what you have is valuable'\n",
      "page_content='ì¹¼ ëì— ì£¼ì›Œ ë¨¹ë‹¤ > Barely survive'\n",
      "page_content='í„¸ ë í•˜ë‚˜ ë‹¤ì¹˜ê²Œ í•˜ì§€ ì•Šê² ë‹¤ > Will protect completely.'\n",
      "page_content='ì„œë‘˜ëŸ¬ì•¼ í•  ì‹œê¸°ë‹¤ > Now is the crucial time'\n"
     ]
    }
   ],
   "source": [
    "test_docs = retriever.invoke('ì˜¤ëŠ˜ë§Œ ë„˜ê¸°ë©´ ì´ì œ ëª©ì— ì¹¼ì´ ë“¤ì–´ì™€ë„ ë„Œ ì•ˆì „í•  ê±°ì•¼.')\n",
    "for d in test_docs:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53b112-463d-4a38-b5f6-a44fe0c5390d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-poetry-env-qdleyyui-py3.10",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
