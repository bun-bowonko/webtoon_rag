{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bac7126-1417-48b0-b9df-3066f0c4cc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bun.2/.cache/pypoetry/virtualenvs/poetry-env-eDEwtiIl-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, BitsAndBytesConfig, AutoConfig\n",
    "from accelerate import Accelerator, infer_auto_device_map\n",
    "\n",
    "LLAMA_PATH = 'model/dpo-240820-ep-line-merged'\n",
    "\n",
    "# 4bit í€€íƒ€ì´ì œì´ì…˜ ì„¤ì •\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_storage=torch.bfloat16,\n",
    "        llm_int8_enable_fp32_cpu_offload=True  # CPU ì˜¤í”„ë¡œë”© í™œì„±í™”\n",
    ")\n",
    "# ê° GPUì— ìµœëŒ€ ë©”ëª¨ë¦¬ ì„¤ì • (ì˜ˆì‹œë¡œ 40GBì”© í• ë‹¹)\n",
    "max_memory = {i: \"40GB\" for i in range(torch.cuda.device_count())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45c68620-1797-4d75-aae5-2e37bcabaf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ì˜ ì„¤ì •ì„ ë¨¼ì € ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "config = AutoConfig.from_pretrained(LLAMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "280cb594-6c13-4290-a887-4b156b8bd1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¹ˆ ëª¨ë¸ ì„ ì–¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "from transformers.modeling_utils import init_empty_weights  # âœ… ì˜¬ë°”ë¥¸ import\n",
    "\n",
    "# ì•„ì§ ëª¨ë¸ì„ ì„ ì–¸í•˜ì§€ ì•Šì€ ìƒíƒœì—ì„œ `config`ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¹ˆ ëª¨ë¸ ìƒì„±\n",
    "# ğŸš€ ê°€ì¤‘ì¹˜ë¥¼ ì „í˜€ ë¡œë“œí•˜ì§€ ì•ŠëŠ” ì™„ì „ ë¹ˆ(empty) ëª¨ë¸ ìƒì„±\n",
    "with init_empty_weights():\n",
    "    empty_model = LlamaForCausalLM(config)\n",
    "print(\"ë¹ˆ ëª¨ë¸ ì„ ì–¸ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8f6bfa-56e7-4497-8aa9-00e2b9cf2a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "# **ğŸš€ GPU 8ëŒ€ì— ê· ë“±í•˜ê²Œ ë¶„ë°°í•˜ëŠ” ìˆ˜ë™ device_map ìƒì„±**\n",
    "device_map = {}\n",
    "\n",
    "# ì„ë² ë”© & ì¶œë ¥ ë ˆì´ì–´ëŠ” GPU 0ì— ë°°ì¹˜\n",
    "device_map[\"model.embed_tokens\"] = 0\n",
    "device_map[\"lm_head\"] = 0\n",
    "\n",
    "# 126ê°œ LlamaDecoderLayerë¥¼ 8ê°œì˜ GPUì— ê· ë“± ë¶„ë°°\n",
    "for i, layer in enumerate(empty_model.model.layers):\n",
    "    assigned_gpu = i % num_gpus  # GPU ì¸ë±ìŠ¤ 0ë¶€í„° 7ê¹Œì§€ ìˆœì°¨ì ìœ¼ë¡œ í• ë‹¹\n",
    "    device_map[f\"model.layers.{i}\"] = assigned_gpu\n",
    "\n",
    "# ë§ˆì§€ë§‰ RMSNormë„ ë§ˆì§€ë§‰ GPUë¡œ ë°°ì¹˜\n",
    "device_map[\"model.norm\"] = 7\n",
    "device_map[\"model.rotary_emb\"] = 7  # Rotary Embeddingë„ ë§ˆì§€ë§‰ GPUë¡œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30c0af9-6a75-4bcc-b5dc-318e4e62e030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 191/191 [22:02<00:00,  6.93s/it]\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ë¡œë“œ (`device_map` ì ìš©)\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    LLAMA_PATH,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map,  # ìë™ ë¶„ë°°ëœ device_map ì ìš©\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b9280cf-c6d1-49af-99e2-e7ab69c39369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained('model/llama_405b_quantized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "895a92bf-2456-4613-a513-0b31badd4c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "TOKENIZER_PATH = 'model/dpo-240820-ep-line-merged'\n",
    "\n",
    "# Tokenizer ë¡œë“œ\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "#tokenizer.save_pretrained('model/llama_405b_quantized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ce02cd5-92e0-46e6-b655-c6ed55f9ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Hugging Face ê³„ì •ì—ì„œ ë°›ì€ API í† í°ì„ ì…ë ¥\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d60dee-9ee9-491e-a1c2-d007e952edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def instruct_structure(prompt,system_prompt=\n",
    "                       \"\"\"You're an expert translator who translates Korean webtoon in English. Make sure the number of target sentences matches the number of source sentences. The result should be TSV formatted. \n",
    "    â€¢ Find a balance between staying true to the Korean meaning and keeping a natural flow. Don't be afraid to add to the text. Embellish it. \n",
    "    â€¢ Avoid translating word-for-word. Keep the general feeling and translate the text accordingly. \n",
    "    â€¢ Translate with an American audience in mind. This means easy-to-read, conversational English.\"\"\"):\n",
    "    input_text, output_text = prompt.split('### target')\n",
    "    input_text = input_text.replace('### glossaries', '### glossary').replace('\\n* ', '\\nâ€¢ ')\n",
    "    input_text = re.sub(r\"\\[[^\\]]+\\] \", \"none \", input_text)\n",
    "    return f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    {system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    {input_text.strip()}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f79e1fd4-374f-444a-9318-b86cfd6afa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bun.2/.cache/pypoetry/virtualenvs/poetry-env-eDEwtiIl-py3.10/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1820: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:00<00:00, 18639.11it/s]\n"
     ]
    }
   ],
   "source": [
    "project_id = \"prod-ai-project\"\n",
    "\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project=project_id)\n",
    "sql = \"\"\"select series_id, episode_id, org_input_text, org_output_text, prompt \n",
    "        from webtoon_translation.structured_240820_ep_line\n",
    "        where data_split = 'romance_valid'\"\"\"\n",
    "df = client.query(sql).result().to_dataframe()\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "df['prompt'] = df['prompt'].progress_apply(lambda x: instruct_structure(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dc15e8b-2031-42cb-b97a-14399b8c986f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "    You're an expert translator who translates Korean webtoon in English. Make sure the number of target sentences matches the number of source sentences. The result should be TSV formatted. \n",
      "    â€¢ Find a balance between staying true to the Korean meaning and keeping a natural flow. Don't be afraid to add to the text. Embellish it. \n",
      "    â€¢ Avoid translating word-for-word. Keep the general feeling and translate the text accordingly. \n",
      "    â€¢ Translate with an American audience in mind. This means easy-to-read, conversational English.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "    ### glossary\n",
      "â€¢ ì•„ë²¨ í—¤ì¼ë¡  (M): abel heylon\n",
      "â€¢ ì•„ë²¨ (M): abel\n",
      "â€¢ í”¼ì˜¤ë‚˜ (F): fiona\n",
      "â€¢ ë§ˆë²•: magic / spell\n",
      "\n",
      "### source\n",
      "000\tnone ë¶ë¶€ ìµœì „ë°© í—¤ì¼ë¡ \n",
      "001\tnone ì—¬ê¸°ê°€ í—¤ì¼ë¡  ê³µì‘ ì„±â€¦.\n",
      "002\tnone ì—„ì²­ë‚œ ìœ„ì••ê°ì´ì•¼â€¦\n",
      "003\tnone ë‚˜ëŠ” ê²°êµ­ ê°€ì¡±ì—ê²Œ ë– ë°€ë ¤ ë¬´ìë¹„í•œ ê³µì‘ì´ ë‹¤ìŠ¤ë¦°ë‹¤ëŠ” ë¶ë¶€ ìµœì „ë°©ì— ì™”ë‹¤.\n",
      "004\tnone ë”± ë´ë„ ë§ˆì™•ì„± ê°™ì€ ê²Œ ì‚¬ëŒ ì—„ì²­ êµ´ë¦´ ê²ƒ ê°™ë‹¤.\n",
      "005\tnone ë‚´ ë¬´ë¤ì„ ë‚´ê°€ íŒ ì§€...\n",
      "006\tnone ì´ìª½ìœ¼ë¡œ.\n",
      "007\tnone ë¬¸ì„ ì—´ì–´ë¼.\n",
      "008\tnone ë¬¸ì´, ì—„ì²­ ì»¤â€¦!!\n",
      "009\tnone ë¶ë¶€ì˜ ê³µì‘, ì•„ë²¨ í—¤ì¼ë¡ \n",
      "010\tnone ë„ˆ ë‚˜ë¦„ëŒ€ë¡œëŠ” ê°ì˜¤í–ˆê² ì§€. í•˜ì§€ë§Œâ€¦\n",
      "011\tnone ë„ˆ ê°™ì€ ì–´ë¦°ì• ëŠ” ì—¬ê¸°ì— í•„ìš” ì—†ë‹¤.\n",
      "012\tnone ì§‘ìœ¼ë¡œ ëŒì•„ê°€ë„ë¡.\n",
      "013\tnone ì“¸ëª¨ì—†ëŠ” ìì—ê²Œ íˆ¬ìí•  ì‹œê°„ì€ ì—†ë‹¤ ì´ê±´ê°€.\n",
      "014\tnone ì•„ë²¨ì€ ëª¨ë¥´ê² ì§€ë§Œ, ì§€ê¸ˆì˜ ë‚˜ëŠ” ë§ˆë•…íˆ ëŒì•„ê°ˆ ê³³ë„ ì—†ì–´.\n",
      "015\tnone ì›ì‘ ì†ì˜, ìì‹ ì˜ ë§ˆë²•ì  ì¬ëŠ¥ì„ ëª¨ë¥´ë˜ í”¼ì˜¤ë‚˜ëŠ”-\n",
      "016\tnone ì´ë ‡ê²Œ ê·¸ë¦° ê°€ë¬¸ì—ì„œë„ í—¤ì¼ë¡ ì—ì„œë„ ì«“ê²¨ë‚œë‹¤.\n",
      "017\tnone ê·¸ë¦¬ê³  ì´ë•Œ ì„¸ìƒì— ë²„ë¦¼ë°›ì€ ìƒì²˜ê°€\n",
      "018\tnone í›„ì— í”¼ì˜¤ë‚˜ê°€ ì•…ì—­ì´ ë˜ëŠ” ê²°ì •ì ì¸ ê³„ê¸°ê°€ ëœë‹¤.\n",
      "019\tnone í•˜ì§€ë§Œ ì§€ê¸ˆì˜ ë‚˜ëŠ” ì•Œê³  ìˆì–´.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
     ]
    }
   ],
   "source": [
    "print(df['prompt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d405a225-add5-439e-9437-6b438c522625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "    You're an expert translator who translates Korean webtoon in English. Make sure the number of target sentences matches the number of source sentences. The result should be TSV formatted. \n",
      "    â€¢ Find a balance between staying true to the Korean meaning and keeping a natural flow. Don't be afraid to add to the text. Embellish it. \n",
      "    â€¢ Avoid translating word-for-word. Keep the general feeling and translate the text accordingly. \n",
      "    â€¢ Translate with an American audience in mind. This means easy-to-read, conversational English.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "    ### glossary\n",
      "â€¢ ì•„ë²¨ í—¤ì¼ë¡  (M): abel heylon\n",
      "â€¢ ì•„ë²¨ (M): abel\n",
      "â€¢ í”¼ì˜¤ë‚˜ (F): fiona\n",
      "â€¢ ë§ˆë²•: magic / spell\n",
      "\n",
      "### source\n",
      "000\tnone ë¶ë¶€ ìµœì „ë°© í—¤ì¼ë¡ \n",
      "001\tnone ì—¬ê¸°ê°€ í—¤ì¼ë¡  ê³µì‘ ì„±â€¦.\n",
      "002\tnone ì—„ì²­ë‚œ ìœ„ì••ê°ì´ì•¼â€¦\n",
      "003\tnone ë‚˜ëŠ” ê²°êµ­ ê°€ì¡±ì—ê²Œ ë– ë°€ë ¤ ë¬´ìë¹„í•œ ê³µì‘ì´ ë‹¤ìŠ¤ë¦°ë‹¤ëŠ” ë¶ë¶€ ìµœì „ë°©ì— ì™”ë‹¤.\n",
      "004\tnone ë”± ë´ë„ ë§ˆì™•ì„± ê°™ì€ ê²Œ ì‚¬ëŒ ì—„ì²­ êµ´ë¦´ ê²ƒ ê°™ë‹¤.\n",
      "005\tnone ë‚´ ë¬´ë¤ì„ ë‚´ê°€ íŒ ì§€...\n",
      "006\tnone ì´ìª½ìœ¼ë¡œ.\n",
      "007\tnone ë¬¸ì„ ì—´ì–´ë¼.\n",
      "008\tnone ë¬¸ì´, ì—„ì²­ ì»¤â€¦!!\n",
      "009\tnone ë¶ë¶€ì˜ ê³µì‘, ì•„ë²¨ í—¤ì¼ë¡ \n",
      "010\tnone ë„ˆ ë‚˜ë¦„ëŒ€ë¡œëŠ” ê°ì˜¤í–ˆê² ì§€. í•˜ì§€ë§Œâ€¦\n",
      "011\tnone ë„ˆ ê°™ì€ ì–´ë¦°ì• ëŠ” ì—¬ê¸°ì— í•„ìš” ì—†ë‹¤.\n",
      "012\tnone ì§‘ìœ¼ë¡œ ëŒì•„ê°€ë„ë¡.\n",
      "013\tnone ì“¸ëª¨ì—†ëŠ” ìì—ê²Œ íˆ¬ìí•  ì‹œê°„ì€ ì—†ë‹¤ ì´ê±´ê°€.\n",
      "014\tnone ì•„ë²¨ì€ ëª¨ë¥´ê² ì§€ë§Œ, ì§€ê¸ˆì˜ ë‚˜ëŠ” ë§ˆë•…íˆ ëŒì•„ê°ˆ ê³³ë„ ì—†ì–´.\n",
      "015\tnone ì›ì‘ ì†ì˜, ìì‹ ì˜ ë§ˆë²•ì  ì¬ëŠ¥ì„ ëª¨ë¥´ë˜ í”¼ì˜¤ë‚˜ëŠ”-\n",
      "016\tnone ì´ë ‡ê²Œ ê·¸ë¦° ê°€ë¬¸ì—ì„œë„ í—¤ì¼ë¡ ì—ì„œë„ ì«“ê²¨ë‚œë‹¤.\n",
      "017\tnone ê·¸ë¦¬ê³  ì´ë•Œ ì„¸ìƒì— ë²„ë¦¼ë°›ì€ ìƒì²˜ê°€\n",
      "018\tnone í›„ì— í”¼ì˜¤ë‚˜ê°€ ì•…ì—­ì´ ë˜ëŠ” ê²°ì •ì ì¸ ê³„ê¸°ê°€ ëœë‹¤.\n",
      "019\tnone í•˜ì§€ë§Œ ì§€ê¸ˆì˜ ë‚˜ëŠ” ì•Œê³  ìˆì–´.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "    000\tthe northernmost region of haylon territory\n",
      "001\tthis is house haylonâ€™s castle...\n",
      "002\tit looks so intimidating!\n",
      "003\tI was forced by my family to come all this way up north where Iâ€™ll have to live under the rule of duke haylon, known for his ruthlessness.\n",
      "004\tfrom what I can see, that place seems like a devil's lair... they must treat people very poorly there.\n",
      "005\thave I dug myself into my own grave?\n",
      "006\tthis way.\n",
      "007\topen the gates.\n",
      "008\tth-the gate is huge...!!!\n",
      "009\tduke abel haylon of the north\n",
      "010\tIâ€™m guessing youâ€™ve prepared yourself,\n",
      "011\tbut we donâ€™t need someone as young as you here.\n",
      "012\tgo back home.\n",
      "013\tis he saying he doesnâ€™t want to waste time on useless people? well, too bad.\n",
      "014\tlittle does abel know, but right now, I donâ€™t really have anywhere else to go.\n",
      "015\tin the original story, since fiona didnâ€™t realize she had magical abilities yet,\n",
      "016\tshe gets kicked out from both her family and house haylon.\n",
      "017\tand when she feels abandoned by everyone around her,\n",
      "018\tthat becomes the turning point which leads her down the path toward becoming the villainess.\n",
      "019\tbut things are different now because I already know about my powers! I wonâ€™t let anyone push me around anymore! no one will ever make me feel unwanted again! I swear!!!<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "sample = df['prompt'][0]\n",
    "\n",
    "# ì…ë ¥ ë³€í™˜ ë° í† í°í™”\n",
    "inputs = tokenizer(sample, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# ëª¨ë¸ ì¶”ë¡ \n",
    "with torch.no_grad():\n",
    "    output = model.generate(**inputs, \n",
    "                            max_length=1000,\n",
    "                            do_sample=True,\n",
    "                            temperature=0.1,\n",
    "                            top_p=0.9,\n",
    "                            top_k=30,\n",
    "                            repetition_penalty=1.2\n",
    "                           )\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d42379-512d-404f-836b-bdaa278a1129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f8ccdb-d0ce-46c4-b53c-44935c8bd314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b4df90-eee0-49d9-b745-0e9adad80a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
